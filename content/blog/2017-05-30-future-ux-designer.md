---
title: The future of the UX-Designer
date: 2017-05-30T19:21:47+00:00
author: Anton Sten
layout: blogpost
image: 'images/blog/Where-is-the-future-of-voice-recognition-and-AI.jpg'
permalink: /future-ux-designer/

---
~~Thereâ€™s been a lot of press lately on how AI-powered assistants will make our lives better/easier/more manageable very soon.~~

Some even think weâ€™re already at that point, but anyone whoâ€™s ever tried Siri, Cortana, or Amazonâ€™s Alexa know that they are all still pretty dumb. However, this has gotten me thinking about what this move from a visually driven interface to a voice controlled interface will mean for us as designers.


> Advances in machine learning mean that voice recognition has gone from a <a href="https://www.slideshare.net/johnmaeda/design-in-tech-report-2017" target="_blank" rel="noopener noreferrer">high error rate (>25%) to a low rate (<5%)</a>â€”i.e. it basically works almost all the time.**<a href="https://www.cooper.com/journal/2017/3/this-is-the-year-of-voice-ui?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+cooper-journal+%28Cooper+Journal%29?" target="_blank" rel="noopener noreferrer">Nate Clinton</a>**

I think the quote above highlights perfectly what has been accomplished so far. Voice recognition HAS improved a lot, but even though Siri may understand what Iâ€™m saying, itâ€™s not the same as saying sheâ€™s able to act on the command. 70% of my Siri queries are still â€˜set a timer for 8 minutesâ€™ when making spaghetti with the other 30% are â€˜start a new outdoor runâ€™. She always gets both of these right, but I would not go that as far as saying it has anything to do with being â€œintelligentâ€.

## When things go wrong

Some of the most overlooked things when creating user experiences is what happens when things go wrong. Sure, there have been some great 404-pages created (hereâ€™s what Mailchimp does), but great user experiences go beyond that. They try to cover every misstep a user might take. What happens if they enter invalid information into a form? What about when they click â€˜Printâ€™ without first selecting an item? Designing for blue skies scenarios is the easier part. It is harder to understand that all user experiences have cloudy days too. Some are even like Bergen, Norway, where itâ€™s raining all day, every day.

Fin, a new AI-powered assistant, is a great example of this. I love how their promo video (below) makes me as a user feel completely empowered by their service. These people, just casually telling their smartphone to carry out all of these chores that no-one wants to do. Have a look:

<iframe class="youtube" width="100%" src="https://www.youtube.com/embed/qLUAtu3a0ds?rel=0" frameborder="0" allowfullscreen></iframe>

Do you notice whatâ€™s not in the videos though? Finâ€™s response. Thereâ€™s no visual or audio confirmation that Fin has understood the input or carried out the requests. They list the tasks on their website, but thereâ€™s no reason to believe that Fin could actually solve these tasks. I could tell Siri all of those things too, just to have her tell me â€œhereâ€™s what I found on the web forâ€¦â€œ (cue sad trombone sound).

As technology offers us more and more options and possibilities, our work as UX-designers will grow to include even more edge-cases. As our acceptance of friction with these services continues to decrease, our work will increasingly need to include more â€˜what ifâ€™ scenarios.

> â€œDesigning for voice and chat will be a sought-after skill in the UX profession in the very near future (now, in fact). The platforms will battle for market share and they will add capabilities rapidly. The SDKs themselves will evolve to be more turnkey, and third parties will join the fray to create tools for makers.â€

So ask your yourself this question:
What will all the highly-skilled Dribble UI designers do? ğŸ˜‰
